app_name: "rcv1"
parameter_name: "rcv1_w"
linear_method {

training_data {
format: TEXT
text: LIBSVM
file: "../data/rcv1/train/part.*"
}

local_cache {
format: BIN
file: "/tmp/rcv1/"
}

model_output {
format: TEXT
file: "../output/rcv1_batch_l2lr_round_adapt"
}

loss {
type: LOGIT
}

# lambda * |w|_1
penalty {
type: L2
lambda: 1
}

learning_rate {
type: CONSTANT
eta: 0.3
}

solver {
# turn it off to elimiate the randomness, but may affects the convergence rate
random_feature_block_order : true
# block-coordinate updating. We divide a feature group into feature_block_ratio
# x nnz_feature_per_instance blocks. If = 0, then use all features
feature_block_ratio : 4
# max number pass of traing data
max_pass_of_data : 20
# bounded-delay consistency
max_block_delay : 4
# convergance critiria. stop if the relative objective <= epsilon
epsilon : 1e-4
# features which occurs <= *tail_feature_count* will be filtered before training
tail_feature_freq : 0
}

lrl2 {

delta_init_value : 5
delta_max_value : 10

round_filter {
type : ADAPT
rtype : RANDOM
#bit_num : 16
}

#kkt_filter {
#threshold_ratio : 100
#}

}

#darling {
# decrease these numbers for harder dataset
#delta_init_value : 5
#delta_max_value : 10
# increasing this number reduces the effect of kkt filter.
#kkt_filter_threshold_ratio : 100
#}

}
